# CI/CD Pipeline for inSight Financial Sentiment Analysis Platform

name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'
  REGISTRY: gcr.io
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  SERVICE_NAME: insight-api
  REGION: us-central1

jobs:
  # Security and Code Quality Checks
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety semgrep

      - name: Run Bandit security scan
        run: |
          bandit -r src/ -f json -o bandit-report.json
          bandit -r src/ -ll

      - name: Run Safety check
        run: safety check --json --output safety-report.json

      - name: Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: auto

      - name: Upload security reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # Code Quality and Linting
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Run Black formatter check
        run: black --check --diff src/ tests/ scripts/

      - name: Run isort import sorting check
        run: isort --check-only --diff src/ tests/ scripts/

      - name: Run flake8 linting
        run: flake8 src/ tests/ scripts/ --output-file=flake8-report.txt

      - name: Run mypy type checking
        run: mypy src/insight/ --junit-xml=mypy-report.xml

      - name: Upload code quality reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: code-quality-reports
          path: |
            flake8-report.txt
            mypy-report.xml

  # Unit and Integration Tests
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: insight_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements*.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Set up test environment
        run: |
          cp env.example .env
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/insight_test" >> .env
          echo "REDIS_URL=redis://localhost:6379/0" >> .env

      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --cov=src/insight --cov-report=xml --cov-report=html

      - name: Run integration tests
        run: |
          pytest tests/integration/ -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Upload test reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-reports-${{ matrix.python-version }}
          path: |
            htmlcov/
            coverage.xml

  # Performance and Load Testing
  performance-test:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install locust

      - name: Start application
        run: |
          uvicorn src.insight.api.app:create_app --host 0.0.0.0 --port 8000 &
          sleep 10

      - name: Run load tests
        run: |
          locust -f tests/performance/locustfile.py --headless --users 50 --spawn-rate 5 --run-time 60s --host http://localhost:8000

      - name: Upload performance reports
        uses: actions/upload-artifact@v3
        with:
          name: performance-reports
          path: performance-results/

  # Docker Build and Security Scan
  docker-build:
    name: Docker Build & Scan
    runs-on: ubuntu-latest
    needs: [security-scan, code-quality, test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: production
          tags: insight:${{ github.sha }}
          load: true
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'insight:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  # Model Training and Validation
  model-training:
    name: Model Training & Validation
    runs-on: ubuntu-latest
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download training data
        run: |
          mkdir -p data/raw
          # In real implementation, download from secure storage
          echo "Training data would be downloaded here"

      - name: Train model
        run: |
          python scripts/train_model.py --epochs 1 --batch-size 8 --quick-test
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}

      - name: Validate model performance
        run: |
          python scripts/validate_model.py --min-f1-score 0.8

      - name: Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: data/models/

  # Staging Deployment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [docker-build, model-training]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Configure Docker for GCR
        run: gcloud auth configure-docker

      - name: Build and push Docker image
        run: |
          docker build -t $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }} .
          docker push $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }}

      - name: Deploy to Cloud Run (Staging)
        run: |
          gcloud run deploy $SERVICE_NAME-staging \
            --image $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }} \
            --platform managed \
            --region $REGION \
            --allow-unauthenticated \
            --set-env-vars "ENVIRONMENT=staging"

      - name: Run E2E tests against staging
        run: |
          pytest tests/e2e/ --base-url=${{ steps.deploy.outputs.url }}

  # Production Deployment
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [docker-build, model-training]
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Configure Docker for GCR
        run: gcloud auth configure-docker

      - name: Build and push Docker image
        run: |
          docker build -t $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }} .
          docker tag $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }} $REGISTRY/$PROJECT_ID/$SERVICE_NAME:latest
          docker push $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }}
          docker push $REGISTRY/$PROJECT_ID/$SERVICE_NAME:latest

      - name: Deploy to Cloud Run (Production)
        run: |
          gcloud run deploy $SERVICE_NAME \
            --image $REGISTRY/$PROJECT_ID/$SERVICE_NAME:${{ github.sha }} \
            --platform managed \
            --region $REGION \
            --allow-unauthenticated \
            --set-env-vars "ENVIRONMENT=production" \
            --min-instances 1 \
            --max-instances 100 \
            --cpu 2 \
            --memory 4Gi

      - name: Verify deployment
        run: |
          sleep 30
          curl -f ${{ steps.deploy.outputs.url }}/api/v1/health

      - name: Run smoke tests
        run: |
          pytest tests/smoke/ --base-url=${{ steps.deploy.outputs.url }}

  # Notification and Monitoring Setup
  notify:
    name: Notify Deployment
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()
    
    steps:
      - name: Notify Slack
        uses: 8398a7/action-slack@v3
        if: github.ref == 'refs/heads/main'
        with:
          status: ${{ needs.deploy-production.result }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          fields: repo,message,commit,author,action,eventName,ref,workflow

      - name: Update status badge
        if: github.ref == 'refs/heads/main'
        run: |
          echo "Deployment status: ${{ needs.deploy-production.result }}" > deployment-status.txt

  # Release Management
  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: github.event_name == 'release'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate changelog
        run: |
          echo "# Release Notes" > RELEASE_NOTES.md
          echo "" >> RELEASE_NOTES.md
          echo "## Changes in this release:" >> RELEASE_NOTES.md
          git log --pretty=format:"- %s" $(git describe --tags --abbrev=0 HEAD^)..HEAD >> RELEASE_NOTES.md

      - name: Create Release Archive
        run: |
          tar -czf insight-${{ github.event.release.tag_name }}.tar.gz \
            --exclude='.git' \
            --exclude='*.tar.gz' \
            --exclude='venv' \
            --exclude='__pycache__' \
            .

      - name: Upload Release Asset
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          upload_url: ${{ github.event.release.upload_url }}
          asset_path: ./insight-${{ github.event.release.tag_name }}.tar.gz
          asset_name: insight-${{ github.event.release.tag_name }}.tar.gz
          asset_content_type: application/gzip

# Cleanup old workflow runs
cleanup:
  name: Cleanup
  runs-on: ubuntu-latest
  if: github.event_name == 'schedule'
  
  steps:
    - name: Delete old workflow runs
      uses: Mattraks/delete-workflow-runs@v2
      with:
        token: ${{ github.token }}
        repository: ${{ github.repository }}
        retain_days: 30
        keep_minimum_runs: 10
